#!/bin/bash
# Test that all files under the `dag` folder can be parsed by Airflow. This can
# be run as follows:
#
#   TESTING=1 bin/test-parse
#
export TESTING=${TESTING:-0}


function inject_failing_dags() {
    # A global variable to help scope testing resource initialization and
    # cleanup in this function. Update this variable when new tests are added.
    export EXPECTED_NUM_ERRORS=1

    export test_0="dags/bin_test_parse_variable_not_exist.py"
    tee << EOF > ${test_0}
from airflow import DAG
from airflow.models import Variable
Variable.get('non_existent_variable')
EOF

    function cleanup_with_tests() {
        docker-compose down
        rm "${test_0}"
    }
    trap cleanup_with_tests EXIT
}


function get_errors_in_listing {
    set -x
    # spawn in the background
    docker-compose up --detach

    # Block until the signal has been seen in the airflow logs. If all the dummy
    # credentials and variables have been set, then the UI and CLI should be in a
    # working state. If docker compose has been previously run, there may be logs
    # from the last run. Setting the tail option ignores previous log files. We
    # parse the stdout stream until we reach the end of the initialization script in
    # `bin/run`.
    # Reference: https://docs.docker.com/compose/reference/logs/
    docker-compose logs --follow --tail 0 | sed -n '/\[testing_stage_0\]/q'

    # Parse the logs for ERROR messages, these typically correspond to python
    # exceptions in the DAG. In general, there should NOT be any errors when
    # runnning the local environment.
    docker-compose exec web airflow dags list -v | grep "ERROR"
}


function main() {
    if [[ -n $(docker-compose ps -q web) ]]; then
        echo "Existing container is up, please bring it down and re-run."
        exit 1
    fi
    
    # Register the cleanup function, note that the testing function may override
    # the trap on the exit signal.
    function cleanup {
        docker-compose down
    }
    trap cleanup EXIT

    if [[ $TESTING -eq 1 ]]; then
        echo "Running in testing mode..."
        inject_failing_dags
    fi

    # Starting the container and error checking routine
    echo "Waiting for airflow to boot, run 'docker-compose tail -f' to follow along..."
    local errors;
    errors=$(get_errors_in_listing)
    local num_errors=$(($(echo "${errors}" | sed '/^$/d' | wc -l)))

    echo "DAG listing contains ${num_errors} errors in log"
    echo "${errors}"

    if [[ $num_errors -ne 0 && $TESTING -eq 0 ]]; then
        # Print full error output
        docker-compose exec web airflow dags list -v
        echo "Failure!"
        exit 1
    elif [[ $TESTING -eq 1 ]]; then
        if [[ $EXPECTED_NUM_ERRORS -ne $num_errors ]]; then
            echo "Wrong number of errors: got $num_errors, expected $EXPECTED_NUM_ERRORS"
            exit 1
        fi
        echo "Unit tests passed!"
    fi

    echo "All checks passed, the dags can be parsed locally."
}


if [[ "${BASH_SOURCE[0]}" == "${0}" ]]; then
    main "$@"
fi
