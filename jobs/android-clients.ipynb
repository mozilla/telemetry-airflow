{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "---\n",
    "title: \"Android Clients ETL\"\n",
    "authors:\n",
    "- Frank Bertsch\n",
    "tags:\n",
    "- mobile\n",
    "- fennec\n",
    "- etl\n",
    "created_at: 2017-02-09\n",
    "updated_at: 2017-02-09\n",
    "tldr: This notebook maps Fennec saved_session pings to some useful information about clients. This is a 1:1 mapping.\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "import os\n",
    "import pandas as pd\n",
    "import ujson as json\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "from moztelemetry import get_pings, get_pings_properties\n",
    "\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take the set of pings, make sure we have actual clientIds and remove duplicate pings. We collect each unique ping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def dedupe_pings(rdd):\n",
    "    return rdd.filter(lambda p: p[\"meta/clientId\"] is not None)\\\n",
    "              .map(lambda p: (p[\"meta/documentId\"], p))\\\n",
    "              .reduceByKey(lambda x, y: x)\\\n",
    "              .map(lambda x: x[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform and sanitize the pings into arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# bug 1362659 - int values exceeded signed 32 bit range\n",
    "MAX_INT = (2**31)-1\n",
    "\n",
    "def transform(ping):\n",
    "    # Should not be None since we filter those out.\n",
    "    clientId = ping[\"meta/clientId\"]\n",
    "\n",
    "    profileDate = None\n",
    "    profileDaynum = ping[\"environment/profile/creationDate\"]\n",
    "    if profileDaynum is not None:\n",
    "        try:\n",
    "            # Bad data could push profileDaynum > 32767 (size of a C int) and throw exception\n",
    "            profileDate = dt.datetime(1970, 1, 1) + dt.timedelta(int(profileDaynum))\n",
    "        except:\n",
    "            profileDate = None\n",
    "\n",
    "    # Create date should already be in ISO format\n",
    "    creationDate = ping[\"creationDate\"]\n",
    "    if creationDate is not None:\n",
    "        # This is only accurate because we know the creation date is always in 'Z' (zulu) time.\n",
    "        creationDate = dt.datetime.strptime(ping[\"creationDate\"], \"%Y-%m-%dT%H:%M:%S.%fZ\")\n",
    "\n",
    "    # Added via the ingestion process so should not be None.\n",
    "    submissionDate = dt.datetime.strptime(ping[\"meta/submissionDate\"], \"%Y%m%d\")\n",
    "\n",
    "    appVersion = ping[\"application/version\"]\n",
    "    osVersion = ping[\"environment/system/os/version\"]\n",
    "    if osVersion is not None:\n",
    "        osVersion = int(osVersion) if int(osVersion) <= MAX_INT else None\n",
    "            \n",
    "    locale = ping[\"environment/settings/locale\"]\n",
    "    \n",
    "    # Truncate to 32 characters\n",
    "    defaultSearch = ping[\"environment/settings/defaultSearchEngine\"]\n",
    "    if defaultSearch is not None:\n",
    "        defaultSearch = defaultSearch[0:32]\n",
    "\n",
    "    # Build up the device string, truncating like we do in 'core' ping.\n",
    "    device = ping[\"environment/system/device/manufacturer\"]\n",
    "    model = ping[\"environment/system/device/model\"]\n",
    "    if device is not None and model is not None:\n",
    "        device = device[0:12] + \"-\" + model[0:19]\n",
    "\n",
    "    xpcomABI = ping[\"application/xpcomAbi\"]\n",
    "    arch = \"arm\"\n",
    "    if xpcomABI is not None and \"x86\" in xpcomABI:\n",
    "        arch = \"x86\"\n",
    "        \n",
    "    # Bug 1337896\n",
    "    as_topsites_loader_time = ping[\"payload/histograms/FENNEC_ACTIVITY_STREAM_TOPSITES_LOADER_TIME_MS\"]\n",
    "    topsites_loader_time = ping[\"payload/histograms/FENNEC_TOPSITES_LOADER_TIME_MS\"]\n",
    "    \n",
    "    if as_topsites_loader_time is not None:\n",
    "        as_topsites_loader_time = map(int, as_topsites_loader_time.tolist())\n",
    "        if any([v > MAX_INT for v in as_topsites_loader_time]):\n",
    "            as_topsites_loader_time = None\n",
    "    \n",
    "    if topsites_loader_time is not None:\n",
    "        topsites_loader_time = map(int, topsites_loader_time.tolist())\n",
    "        if any([v > MAX_INT for v in topsites_loader_time]):\n",
    "            topsites_loader_time = None\n",
    "\n",
    "    return [clientId,\n",
    "            profileDate,\n",
    "            submissionDate,\n",
    "            creationDate,\n",
    "            appVersion,\n",
    "            osVersion,\n",
    "            locale,\n",
    "            defaultSearch,\n",
    "            device,\n",
    "            arch,\n",
    "            as_topsites_loader_time,\n",
    "            topsites_loader_time]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a set of pings from \"saved-session\" to build a set of core client data. Output the data to CSV or Parquet.\n",
    "\n",
    "This script is designed to loop over a range of days and output a single day for the given channels. Use explicit date ranges for backfilling, or now() - '1day' for automated runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "channels = [\"nightly\", \"aurora\", \"beta\", \"release\"]\n",
    "\n",
    "batch_date = os.environ.get('date')\n",
    "if batch_date:\n",
    "    start = end = dt.datetime.strptime(batch_date, '%Y%m%d')\n",
    "else:\n",
    "    start = end = dt.datetime.now() - dt.timedelta(1)\n",
    "\n",
    "day = start\n",
    "while day <= end:\n",
    "    for channel in channels:\n",
    "        print \"\\nchannel: \" + channel + \", date: \" + day.strftime(\"%Y%m%d\")\n",
    "\n",
    "        pings = get_pings(sc, app=\"Fennec\", channel=channel,\n",
    "                          submission_date=(day.strftime(\"%Y%m%d\"), day.strftime(\"%Y%m%d\")),\n",
    "                          build_id=(\"20100101000000\", \"99999999999999\"),\n",
    "                          fraction=1)\n",
    "\n",
    "        subset = get_pings_properties(pings, [\"meta/clientId\",\n",
    "                                              \"meta/documentId\",\n",
    "                                              \"meta/submissionDate\",\n",
    "                                              \"creationDate\",\n",
    "                                              \"application/version\",\n",
    "                                              \"environment/system/os/version\",\n",
    "                                              \"environment/profile/creationDate\",\n",
    "                                              \"environment/settings/locale\",\n",
    "                                              \"environment/settings/defaultSearchEngine\",\n",
    "                                              \"environment/system/device/model\",\n",
    "                                              \"environment/system/device/manufacturer\",\n",
    "                                              \"application/xpcomAbi\",\n",
    "                                              \"payload/histograms/FENNEC_ACTIVITY_STREAM_TOPSITES_LOADER_TIME_MS\",\n",
    "                                              \"payload/histograms/FENNEC_TOPSITES_LOADER_TIME_MS\"])\n",
    "\n",
    "        subset = dedupe_pings(subset)\n",
    "        transformed = subset.map(transform)\n",
    "\n",
    "        s3_output = \"s3n://net-mozaws-prod-us-west-2-pipeline-analysis/mobile/android_clients\"\n",
    "        s3_output += \"/v2/channel=\" + channel + \"/submission=\" + day.strftime(\"%Y%m%d\") \n",
    "        schema = StructType([\n",
    "            StructField(\"clientid\", StringType(), False),\n",
    "            StructField(\"profiledate\", TimestampType(), True),\n",
    "            StructField(\"submissiondate\", TimestampType(), False),\n",
    "            StructField(\"creationdate\", TimestampType(), True),\n",
    "            StructField(\"appversion\", StringType(), True),\n",
    "            StructField(\"osversion\", IntegerType(), True),\n",
    "            StructField(\"locale\", StringType(), True),\n",
    "            StructField(\"defaultsearch\", StringType(), True),\n",
    "            StructField(\"device\", StringType(), True),\n",
    "            StructField(\"arch\", StringType(), True),\n",
    "            StructField(\"fennec_activity_stream_topsites_loader_time_ms\", \n",
    "                        ArrayType(IntegerType()), \n",
    "                        True\n",
    "            ),\n",
    "            StructField(\"fennec_topsites_loader_time_ms\", \n",
    "                        ArrayType(IntegerType()), \n",
    "                        True\n",
    "            )\n",
    "        ])\n",
    "        grouped = sqlContext.createDataFrame(transformed, schema)\n",
    "        grouped.coalesce(1).write.parquet(s3_output, mode=\"overwrite\")\n",
    "\n",
    "    day += dt.timedelta(1)\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}