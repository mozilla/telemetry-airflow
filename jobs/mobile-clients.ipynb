{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Mobile Clients ETL Job\"\n",
    "authors:\n",
    "- Frank Bertsch\n",
    "tags:\n",
    "- mobile\n",
    "- etl\n",
    "created_at: 2017-02-17\n",
    "updated_at: 2017-02-17\n",
    "tldr: This job basically just takes core pings and puts them in parquet format.\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime as dt\n",
    "import pandas as pd\n",
    "import ujson as json\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "from moztelemetry import get_pings, get_pings_properties\n",
    "\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take the set of pings, make sure we have actual clientIds and remove duplicate pings. We collect each unique ping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def dedupe_pings(rdd):\n",
    "    return rdd.filter(lambda p: p[\"meta/clientId\"] is not None)\\\n",
    "              .map(lambda p: (p[\"meta/documentId\"], p))\\\n",
    "              .reduceByKey(lambda x, y: x)\\\n",
    "              .map(lambda x: x[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform and sanitize the pings into arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def transform(ping):\n",
    "    # Should not be None since we filter those out.\n",
    "    clientId = ping[\"meta/clientId\"]\n",
    "\n",
    "    # Added via the ingestion process so should not be None.\n",
    "    submissionDate = dt.datetime.strptime(ping[\"meta/submissionDate\"], \"%Y%m%d\")\n",
    "    geoCountry = ping[\"meta/geoCountry\"]\n",
    "\n",
    "    profileDate = None\n",
    "    profileDaynum = ping[\"profileDate\"]\n",
    "    if profileDaynum is not None:\n",
    "        try:\n",
    "            # Bad data could push profileDaynum > 32767 (size of a C int) and throw exception\n",
    "            profileDate = dt.datetime(1970, 1, 1) + dt.timedelta(int(profileDaynum))\n",
    "        except:\n",
    "            profileDate = None\n",
    "\n",
    "    # Create date can be an improper string (~.03% of the time, so ignore)\n",
    "    # Year can be < 2000 (~.005% of the time, so ignore)\n",
    "    try: \n",
    "        # Create date should already be in ISO format\n",
    "        creationDate = ping[\"created\"]\n",
    "        if creationDate is not None:\n",
    "            # This is only accurate because we know the creation date is always in 'Z' (zulu) time.\n",
    "            creationDate = dt.datetime.strptime(ping[\"created\"], \"%Y-%m-%d\")\n",
    "            if creationDate.year < 2000:\n",
    "                creationDate = None\n",
    "    except ValueError:\n",
    "        creationDate = None\n",
    "\n",
    "    appVersion = ping[\"meta/appVersion\"]\n",
    "    buildId = ping[\"meta/appBuildId\"]\n",
    "    locale = ping[\"locale\"]\n",
    "    os = ping[\"os\"]\n",
    "    osVersion = ping[\"osversion\"]\n",
    "    device = ping[\"device\"]\n",
    "    arch = ping[\"arch\"]\n",
    "    defaultSearch = ping[\"defaultSearch\"]\n",
    "    distributionId = ping[\"distributionId\"]\n",
    "\n",
    "    experiments = ping[\"experiments\"]\n",
    "    if experiments is None:\n",
    "        experiments = []\n",
    "        \n",
    "    #bug 1315028\n",
    "    defaultNewTabExperience = ping[\"defaultNewTabExperience\"]\n",
    "    defaultMailClient = ping[\"defaultMailClient\"]\n",
    "\n",
    "    #bug 1307419\n",
    "    searches = ping[\"searches\"]\n",
    "    durations = ping[\"durations\"]\n",
    "    sessions = ping[\"sessions\"]\n",
    "    \n",
    "    return [clientId, submissionDate, creationDate, profileDate, geoCountry, locale, os,\n",
    "            osVersion, buildId, appVersion, device, arch, defaultSearch, distributionId,\n",
    "            json.dumps(experiments), defaultNewTabExperience, defaultMailClient, searches,\n",
    "            durations, sessions]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a set of pings from \"core\" to build a set of core client data. Output the data to CSV or Parquet.\n",
    "\n",
    "This script is designed to loop over a range of days and output a single day for the given channels. Use explicit date ranges for backfilling, or now() - '1day' for automated runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "channels = [\"nightly\", \"aurora\", \"beta\", \"release\"]\n",
    "\n",
    "batch_date = os.environ.get('date')\n",
    "if batch_date:\n",
    "    start = end = dt.datetime.strptime(batch_date, '%Y%m%d')\n",
    "else:\n",
    "    start = dt.datetime.now() - dt.timedelta(1)\n",
    "    end = dt.datetime.now() - dt.timedelta(1)\n",
    "\n",
    "\n",
    "\n",
    "day = start\n",
    "while day <= end:\n",
    "    for channel in channels:\n",
    "        print \"\\nchannel: \" + channel + \", date: \" + day.strftime(\"%Y%m%d\")\n",
    "\n",
    "        kwargs = dict(\n",
    "            doc_type=\"core\",\n",
    "            submission_date=(day.strftime(\"%Y%m%d\"), day.strftime(\"%Y%m%d\")),\n",
    "            channel=channel,\n",
    "            app=\"Fennec\",\n",
    "            fraction=1\n",
    "        )\n",
    "\n",
    "        # Grab all available source_version pings\n",
    "        pings = get_pings(sc, source_version=\"*\", **kwargs)\n",
    "\n",
    "        subset = get_pings_properties(pings, [\"meta/clientId\",\n",
    "                                              \"meta/documentId\",\n",
    "                                              \"meta/submissionDate\",\n",
    "                                              \"meta/appVersion\",\n",
    "                                              \"meta/appBuildId\",\n",
    "                                              \"meta/geoCountry\",\n",
    "                                              \"locale\",\n",
    "                                              \"os\",\n",
    "                                              \"osversion\",\n",
    "                                              \"device\",\n",
    "                                              \"arch\",\n",
    "                                              \"profileDate\",\n",
    "                                              \"created\",\n",
    "                                              \"defaultSearch\",\n",
    "                                              \"distributionId\",\n",
    "                                              \"experiments\",\n",
    "                                              \"defaultNewTabExperience\",\n",
    "                                              \"defaultMailClient\",\n",
    "                                              \"searches\",\n",
    "                                              \"durations\",\n",
    "                                              \"sessions\"])\n",
    "\n",
    "        subset = dedupe_pings(subset)\n",
    "        print \"\\nDe-duped pings:\" + str(subset.count())\n",
    "        print subset.first()\n",
    "\n",
    "        transformed = subset.map(transform)\n",
    "        print \"\\nTransformed pings:\" + str(transformed.count())\n",
    "        print transformed.first()\n",
    "\n",
    "        s3_output = \"s3n://net-mozaws-prod-us-west-2-pipeline-analysis/mobile/mobile_clients\"\n",
    "        s3_output += \"/v2/channel=\" + channel + \"/submission=\" + day.strftime(\"%Y%m%d\") \n",
    "        schema = StructType([\n",
    "            StructField(\"clientid\", StringType(), False),\n",
    "            StructField(\"submissiondate\", TimestampType(), False),\n",
    "            StructField(\"creationdate\", TimestampType(), True),\n",
    "            StructField(\"profiledate\", TimestampType(), True),\n",
    "            StructField(\"geocountry\", StringType(), True),\n",
    "            StructField(\"locale\", StringType(), True),\n",
    "            StructField(\"os\", StringType(), True),\n",
    "            StructField(\"osversion\", StringType(), True),\n",
    "            StructField(\"buildid\", StringType(), True),\n",
    "            StructField(\"appversion\", StringType(), True),\n",
    "            StructField(\"device\", StringType(), True),\n",
    "            StructField(\"arch\", StringType(), True),\n",
    "            StructField(\"defaultsearch\", StringType(), True),\n",
    "            StructField(\"distributionid\", StringType(), True),\n",
    "            StructField(\"experiments\", StringType(), True),\n",
    "            StructField(\"default_new_tab_experience\", StringType(), True),\n",
    "            StructField(\"default_mail_client\", StringType(), True),\n",
    "            StructField(\"searches\", StringType(), True),\n",
    "            StructField(\"durations\", StringType(), True),\n",
    "            StructField(\"sessions\", StringType(), True)\n",
    "        ])\n",
    "        # Make parquet parition file size large, but not too large for s3 to handle\n",
    "        coalesce = 1\n",
    "        if channel == \"release\":\n",
    "            coalesce = 4\n",
    "        grouped = sqlContext.createDataFrame(transformed, schema)\n",
    "        grouped.coalesce(coalesce).write.mode('overwrite').parquet(s3_output)\n",
    "\n",
    "    day += dt.timedelta(1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}