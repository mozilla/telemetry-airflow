- name: provision aws resources
  hosts: localhost
  vars:
    elb_name: telemetry-ecs
    command: scheduler

  tasks:
    - name: create bucket
      s3: bucket={{airflow_bucket}} region={{region}} mode=create

    - name: copy EMR bootstrap script
      s3: bucket={{airflow_bucket}} region={{region}} object=steps/airflow.sh src=ansible/files/spark/airflow.sh mode=put

    - name: create load balancer
      ec2_elb_lb:
        name: "{{ elb_name }}"
        region: "{{ region }}"
        state: present
        security_group_names: "{{ elb_sg_name }}"
        subnets:
          - "{{ ecs_vpc_subnet_id }}"
        listeners:
          - protocol: https
            load_balancer_port: 443
            instance_protocol: http
            instance_port: 8080
            ssl_certificate_id: "{{ ssl_cert_id }}"
          - protocol: http
            load_balancer_port: 80
            instance_port: 8080
        health_check:
          ping_protocol: tcp
          ping_port: 8080
          response_timeout: 50 # seconds
          interval: 60 # seconds
          unhealthy_threshold: 2
          healthy_threshold: 2

    - name: fetch SMTP credentials
      s3: bucket={{metadata_bucket}} region={{region}} object=smtp_ses/credentials.json mode=getstr
      register: smtp_credentials_json

    - set_fact:
        smtp_credentials: "{{ smtp_credentials_json.contents|from_json }}"

    - name: create task definition
      shell: "{{ item }}"
      with_items:
        - ecs-cli configure --cluster {{ ecs_cluster_name }}
        - ecs-cli compose --project-name telemetry-airflow --file ansible/files/docker-compose.yml create
      environment:
        AWS_REGION: "{{ region }}"
        EMR_KEY_NAME: "{{ emr_key_name }}"
        EMR_FLOW_ROLE: "{{ emr_flow_role }}"
        EMR_SERVICE_ROLE: "{{ emr_service_role }}"
        EMR_INSTANCE_TYPE: "{{ emr_instance_type }}"
        SPARK_BUCKET: "{{ spark_bucket }}"
        DB_URI: "{{ db_uri }}"
        DB_USER: "{{ db_user }}"
        DB_PASSWORD: "{{ db_password }}"
        AIRFLOW_BUCKET: "{{ airflow_bucket }}"
        AIRFLOW_ENABLE_AUTH: True
        PRIVATE_OUTPUT_BUCKET: "{{ private_output_bucket }}"
        PUBLIC_OUTPUT_BUCKET: "{{ public_output_bucket }}"
        SMTP_HOST: "{{ smtp_credentials.host }}"
        SMTP_USER: "{{ smtp_credentials.user }}"
        SMTP_PASSWORD: "{{ smtp_credentials.password }}"
        # Bug 1286825: Tell the scheduler to exit after 5 runs.
        COMMAND: scheduler -n 5 # https://github.com/aws/amazon-ecs-cli/issues/28

    # TODO: create a new module capable of updating the service with the new definition or ensure that the
    # revision of a new task definition is incremental (for some reason it's not always the case...)
    - name: update service
      ecs_service:
        region: "{{ region }}"
        name: telemetry-airflow
        cluster: "{{ ecs_cluster_name }}"
        desired_count: 1
        state: present
        role: "{{ ecs_role }}"
        load_balancers:
          - loadBalancerName: "{{ elb_name }}"
            containerName: webserver
            containerPort: 8080
        task_definition: ecscompose-telemetry-airflow
