from airflow import DAG
from airflow.sensors.external_task import ExternalTaskSensor
from datetime import timedelta, datetime
from operators.gcp_container_operator import GKEPodOperator
from utils.tags import Tag
from utils.constants import ALLOWED_STATES, FAILED_STATES

DOCS = """
Temporary DAG to synchronize S3 with GCS for CDN backing https://analysis-output.telemetry.mozilla.org
See https://mozilla-hub.atlassian.net/browse/DSRE-951 for details.
"""

default_args = {
    "owner": "whd@mozilla.com",
    "depends_on_past": False,
    "start_date": datetime(2023, 6, 13),
    "email_on_failure": True,
    "email_on_retry": True,
    "retries": 2,
    "retry_delay": timedelta(minutes=30),
}

tags = [Tag.ImpactTier.tier_3]

dags = {
    "app-update": {
        "dag_id": "update_orphaning_dashboard_etl",
        "task_id": "update_orphaning_dashboard_etl",
    },
    "bhr": {
        "dag_id": "bhr_collection",
        "task_id": "bhr_collection",
    },
    "public-data-report": {
        "dag_id": "firefox_public_data_report",
        "task_id": "annotations_export",
    },
    "top-signatures-correlations": {
        "dag_id": "crash_symbolication",
        "task_id": "top_signatures_correlations",
    },
    "gfx": {
        "dag_id": "graphics_telemetry",
        # takes over 10x longer than the other task
        "task_id": "graphics_dashboard",
    }
    # not in active use, doesn't appear to be generated by the hypothesized DAG
    # "telemetry-ml": {
    #     "dag_id": "taar_daily",
    #     "task_id": "",
    # },
}


with DAG(
    "aws_s3_sync",
    doc_md=DOCS,
    default_args=default_args,
    schedule_interval="@daily",
    tags=tags,
) as dag:

    aws_conn_id = "aws_dev_telemetry_public_analysis_2_rw"
    aws_access_key, aws_secret_key, _ = AwsBaseHook(
        aws_conn_id=aws_conn_id, client_type="s3"
    ).get_credentials()

    docker_image = "google/cloud-sdk:slim"
    s3_bucket = "telemetry-public-analysis-2"
    # stage for testing
    gcs_bucket = "moz-fx-data-static-websit-f7e0-analysis-output"

    for prefix, dependency in dags.items():
        wait = ExternalTaskSensor(
            task_id=f"wait_{prefix.replace('-', '_')}",
            external_dag_id=dependency["dag_id"],
            external_task_id=dependency["task_id"],
            execution_delta=timedelta(hours=1),
            check_existence=True,
            mode="reschedule",
            allowed_states=ALLOWED_STATES,
            failed_states=FAILED_STATES,
            pool="DATA_ENG_EXTERNALTASKSENSOR",
            email_on_retry=False,
            dag=dag,
        )

        sync = GKEPodOperator(
            task_id=f"aws_s3_sync_{prefix.replace('-', '_')}",
            name=f"aws-s3-sync-{prefix}",
            image=docker_image,
            arguments=[
                "/google-cloud-sdk/bin/gsutil",
                "-m",
                "rsync",
                "-d",
                "-r",
                f"s3://{s3_bucket}/{prefix}/",
                f"gs://{gcs_bucket}/{prefix}/",
            ],
            env_vars={
                "AWS_ACCESS_KEY_ID": aws_access_key,
                "AWS_SECRET_ACCESS_KEY": aws_secret_key,
            },
            dag=dag,
        )
        wait >> sync
