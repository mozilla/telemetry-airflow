version: '2.1'

services:
  db:
    # platform key added for Macbook M1 compatibility, followed:
    # https://stackoverflow.com/questions/65456814/docker-apple-silicon-m1-preview-mysql-no-matching-manifest-for-linux-arm64-v8
    platform: linux/x86_64
    image: mysql:5.7
    ports:
      - '3306:3306'
    # command: ['--explicit_defaults_for_timestamp=1', '--character-set-server=utf8mb4']
    command: ['--explicit_defaults_for_timestamp=1']
    environment:
       MYSQL_ROOT_PASSWORD: secret
       MYSQL_DATABASE: airflow

  redis:
    image: redis:3.2

  app:
    build:
      context: .
      dockerfile: Dockerfile
    restart: "no"
    volumes:
      - $PWD:/app
      - $PWD/dev_webserver_config.py:/app/webserver_config.py
      # mount a dummy file to google application credentials, if not provided
      - ${GOOGLE_APPLICATION_CREDENTIALS:-./.add_credentials.md}:/tmp/.credentials
    command: "true"
    # Environment variables, exports, and substitution:
    #   https://docs.docker.com/compose/environment-variables/
    # Setting connection strings from environment variables:
    #   https://airflow.apache.org/howto/connection/index.html#creating-a-connection-with-environment-variables
    # Non-intuitive quoting behavior in docker-compose due to list syntax and yaml parsing:
    #   https://github.com/docker/compose/issues/2854#issuecomment-433592364
    environment:
      - AWS_SECRET_ACCESS_KEY
      - AWS_ACCESS_KEY_ID
      - GOOGLE_APPLICATION_CREDENTIALS=/tmp/.credentials
      - PORT=8000
      - DEPLOY_ENVIRONMENT=dev
      - DEVELOPMENT=1
      - AIRFLOW_HOME=/app
      - AIRFLOW_AUTHENTICATE=False
      - AIRFLOW_AUTH_BACKEND=airflow.contrib.auth.backends.password_auth
      - AIRFLOW_BROKER_URL=redis://redis:6379/0
      - AIRFLOW_RESULT_URL=redis://redis:6379/0
      - AIRFLOW_FLOWER_PORT=5555
      - AIRFLOW_DATABASE_URL=mysql://root:secret@db:3306/airflow
      - AIRFLOW__CORE__FERNET_KEY=0000000000000000000000000000000000000000000=
      - AIRFLOW_SECRET_KEY=000000000000000000000000000000000000000000=
      - AIRFLOW_SMTP_FROM=telemetry-alerts@airflow.dev.mozaws.net
      - AIRFLOW__SCHEDULER__CATCHUP_BY_DEFAULT=False
      - AIRFLOW_EMAIL_BACKEND=airflow.macros.log_email_backend.log_email_backend
      - AIRFLOW__KUBERNETES__IN_CLUSTER=False
      - URL=http://localhost:8000
      # URL-encoded dummy connections; note that we define some other connections
      # in the bin/run script
      - AIRFLOW_CONN_ADM_SFTP=ftp://myname:mypassword@myhost.com:8000?known_hosts=myhost.com+AAAABBBBB
      # TODO(hwoo) - improve developer workflow by not loading all dags
      # - AIRFLOW__CORE__DAGS_FOLDER=$AIRFLOW_HOME/devdags

  web:
    extends:
      service: app
    restart: always
    ports:
      - "8000:8000"
    depends_on:
      - app
    links:
      - db
      - redis
    command: web

  worker:
    extends:
      service: app
    restart: always
    mem_limit: "4294967296"
    ports:
      - "8793:8793"
    links:
      - db
      - redis
    command: worker

  scheduler:
    mem_limit: "4294967296"
    extends:
      service: app
    restart: always
    links:
      - db
      - redis
    command: scheduler

  flower:
    extends:
      service: app
    restart: always
    ports:
      - "5555:5555"
    links:
      - redis
    command: flower
